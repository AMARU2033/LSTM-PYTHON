{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import operator\n",
    "from theano.gradient import grad_clip\n",
    "from utils import *\n",
    "from lstm_theano import *\n",
    "from gru_theano import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Stanford pre-trained glove vectors\n",
    "gdic, gvec = load_stanford_glove(\"data/glove/glove.6B.100d.txt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "Parsed 76456 sentences.\n",
      "Found 58100 unique words tokens.\n",
      "Using vocabulary size 2000.\n",
      "The least frequent word in our vocabulary is 'hardly' and appeared 54 times.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from utils import load_and_proprocess_data\n",
    "VOCABULARY_SIZE = 2000\n",
    "X_train, y_train, word_to_index, index_to_word = load_and_proprocess_data(VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct glove word vectors for vocabulary\n",
    "wv_dim = gvec.shape[1]\n",
    "wv = []\n",
    "for i in range(VOCABULARY_SIZE):\n",
    "    word = index_to_word[i]\n",
    "    if word not in gdic:\n",
    "        wv.append(np.zeros(wv_dim))\n",
    "    else:\n",
    "        wv.append(gvec[gdic[word]])\n",
    "wv = np.array(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GRUTheano:\n",
    "    \n",
    "    def __init__(self, word_dim, hidden_dim=100, reg_lambda=0, wordvec=None, bptt_truncate=-1):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Initialize the network parameters\n",
    "        if wordvec != None:\n",
    "            U = np.array([wordvec.T, wordvec.T, wordvec.T])\n",
    "        else:\n",
    "            U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (3, hidden_dim, word_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (9, hidden_dim, hidden_dim))\n",
    "        b = np.zeros((6, hidden_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        \n",
    "        c = np.zeros(word_dim)\n",
    "        # Theano: Created shared variables\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        # Bias terms\n",
    "        self.b = theano.shared(name='b_i', value=b.astype(theano.config.floatX))\n",
    "        self.c = theano.shared(name='c', value=c.astype(theano.config.floatX))\n",
    "        # SGD: Initialize parameters\n",
    "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
    "        self.mc = theano.shared(name='mc', value=np.zeros(c.shape).astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()\n",
    "    \n",
    "    def __theano_build__(self):\n",
    "        V, U, W, b, c = self.V, self.U, self.W, self.b, self.c\n",
    "        \n",
    "        x = T.ivector('x')\n",
    "        y = T.ivector('y')\n",
    "        \n",
    "        def forward_prop_step(x_t, s_t_prev, s_t2_prev):\n",
    "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
    "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t_prev))\n",
    "            \n",
    "            # Clip the gradients\n",
    "            W_clipped = grad_clip(W, -1, 1)\n",
    "            U_clipped = grad_clip(U, -1, 1)\n",
    "            V_clipped = grad_clip(V, -1, 1)\n",
    "            b_clipped = grad_clip(b, -1, 1)\n",
    "            c_clipped = grad_clip(c, -1, 1)\n",
    "            \n",
    "            # LRU hidden state calculation\n",
    "            z_t = T.nnet.sigmoid(U_clipped[0][:,x_t] + W_clipped[0].dot(s_t_prev) + b_clipped[0])\n",
    "            r_t = T.nnet.sigmoid(U_clipped[1][:,x_t] + W_clipped[1].dot(s_t_prev) + b_clipped[1])\n",
    "            c_t = T.tanh(U_clipped[2][:,x_t] + W_clipped[2].dot(s_t_prev) * r_t + b_clipped[2])\n",
    "            s_t = (1 - z_t) * c_t + z_t * s_t_prev\n",
    "            \n",
    "            # Layer 2\n",
    "            z_t2 = T.nnet.sigmoid(W_clipped[3].dot(s_t) + W_clipped[6].dot(s_t2_prev) + b_clipped[3])\n",
    "            r_t2 = T.nnet.sigmoid(W_clipped[4].dot(s_t) + W_clipped[7].dot(s_t2_prev) + b_clipped[4])\n",
    "            c_t2 = T.tanh(W_clipped[5].dot(s_t) + W_clipped[8].dot(s_t2_prev) * r_t2 + b_clipped[5])\n",
    "            s_t2 = (1 - z_t2) * c_t2 + z_t2 * s_t2_prev            \n",
    "              \n",
    "            # Final output calculation\n",
    "            # Theano's softmax returns a matrix with one row, we only need the row\n",
    "            o_t = T.nnet.softmax(V_clipped.dot(s_t2) + c_clipped)[0]\n",
    "\n",
    "            return [o_t, s_t, s_t2]\n",
    "        \n",
    "        [o,s,s2], updates = theano.scan(\n",
    "            forward_prop_step,\n",
    "            sequences=x,\n",
    "            truncate_gradient=self.bptt_truncate,\n",
    "            outputs_info=[None, dict(initial=T.zeros(self.hidden_dim)), dict(initial=T.zeros(self.hidden_dim))])\n",
    "        \n",
    "        prediction = T.argmax(o, axis=1)\n",
    "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        \n",
    "        # Regularization cost\n",
    "        reg_cost = self.reg_lambda/2. * \\\n",
    "            (T.sum(T.sqr(V)) + T.sum(T.sqr(U)) + T.sum(T.sqr(W)) + T.sum(T.sqr(b)) + T.sum(T.sqr(c)))\n",
    "        # Total cost\n",
    "        cost = o_error + reg_cost\n",
    "        \n",
    "        # Gradients\n",
    "        dU = T.grad(cost, U)\n",
    "        dW = T.grad(cost, W)\n",
    "        db = T.grad(cost, b)\n",
    "        dV = T.grad(cost, V)\n",
    "        dc = T.grad(cost, c)\n",
    "        \n",
    "        # Assign functions\n",
    "        self.forward_propagation = theano.function([x], o)\n",
    "        self.predict = theano.function([x], prediction)\n",
    "        self.ce_error = theano.function([x, y], cost)\n",
    "        self.bptt = theano.function([x, y], [dU, dW, db, dV, dc])\n",
    "        \n",
    "        # SGD parameters\n",
    "        learning_rate = T.scalar('learning_rate')\n",
    "        decay = T.scalar('decay')\n",
    "        \n",
    "        # rmsprop cache updates\n",
    "        mU = decay * self.mU + (1 - decay) * T.sqr(dU)\n",
    "        mW = decay * self.mW + (1 - decay) * T.sqr(dW)\n",
    "        mV = decay * self.mV + (1 - decay) * T.sqr(dV)\n",
    "        mb = decay * self.mb + (1 - decay) * T.sqr(db)\n",
    "        mc = decay * self.mc + (1 - decay) * T.sqr(dc)\n",
    "        \n",
    "        self.sgd_step = theano.function(\n",
    "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
    "            [], \n",
    "            updates=[(U, U - learning_rate * dU / T.sqrt(mU + 1e-8)),                     \n",
    "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-8)),\n",
    "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-8)),\n",
    "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-8)),\n",
    "                     (c, c - learning_rate * dc / T.sqrt(mc + 1e-8)),\n",
    "                     (self.mU, mU),\n",
    "                     (self.mW, mW),\n",
    "                     (self.mV, mV),\n",
    "                     (self.mb, mb),\n",
    "                     (self.mc, mc)\n",
    "                    ])\n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        return np.sum([self.ce_error(x,y) for x,y in zip(X,Y)])\n",
    "    \n",
    "    def calculate_loss(self, X, Y):\n",
    "        # Divide calculate_loss by the number of words\n",
    "        num_words = np.sum([len(y) for y in Y])\n",
    "        return self.calculate_total_loss(X,Y)/float(num_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gradient check for parameter U with size 3000.\n",
      "Gradient check for parameter U passed.\n",
      "Performing gradient check for parameter W with size 900.\n",
      "Gradient check for parameter W passed.\n",
      "Performing gradient check for parameter b with size 60.\n",
      "Gradient check for parameter b passed.\n",
      "Performing gradient check for parameter V with size 1000.\n",
      "Gradient check for parameter V passed.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "GRUTheano instance has no attribute 'b2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-de72aaac50ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUTheano\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgradient_check_theano\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/utils.py\u001b[0m in \u001b[0;36mgradient_check_theano\u001b[0;34m(model, x, y, h, error_threshold)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Get the actual parameter value from the mode, e.g. model.W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mparameter_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Performing gradient check for parameter %s with size %d.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: GRUTheano instance has no attribute 'b2'"
     ]
    }
   ],
   "source": [
    "# Do a gradient check\n",
    "np.random.seed(0)\n",
    "model = GRUTheano(100, 10)\n",
    "gradient_check_theano(model, [0,1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load parameters of pre-trained model\n",
    "# model = load_model_parameters_theano('./data/2015-10-18/GRUTheano-80-8000-10.npz', GRUTheano)\n",
    "model = load_model_parameters_theano('./data/pretrained.npz', GRUTheano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Step time: 121.037960 milliseconds\n",
      "2015-10-20 11:51:18: Loss after num_examples_seen=0 epoch=0: 7.614625\n",
      "2015-10-20 11:52:16: Loss after num_examples_seen=500 epoch=1: 6.182702\n",
      "2015-10-20 11:53:11: Loss after num_examples_seen=1000 epoch=2: 6.134361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-a2b4445ab123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"SGD Step time: %f milliseconds\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/utils.py\u001b[0m in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, decay, evaluate_loss_after, subsample_loss, save_every)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# One SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mnum_examples_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    670\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/dennybritz/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4585)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load parameters of pre-trained model\n",
    "# model = load_model_parameters_theano('./data/2015-10-18/GRUTheano-80-8000-10.npz', GRUTheano)\n",
    "# model = load_model_parameters_theano('./data/pretrained.npz', GRUTheano)\n",
    "\n",
    "# Build model and train\n",
    "\n",
    "REGULARIZATION = 0\n",
    "LEARNING_RATE = 1e-4\n",
    "NEPOCH = 50\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "model = GRUTheano(VOCABULARY_SIZE, hidden_dim=HIDDEN_DIM, reg_lambda=REGULARIZATION, wordvec=wv, bptt_truncate=4)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[10], y_train[10], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print \"SGD Step time: %f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train[:500], y_train[:500], LEARNING_RATE, NEPOCH, evaluate_loss_after=1, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best here environment op . to\n",
      "challenge settings enjoyed road . logic . .\n",
      "context apart count environment .\n",
      "watched metal determine the about\n",
      "de jump window somewhat your it . be\n",
      "period lost life . ?\n",
      "final europe goal well through option game it\n",
      "led finding be taxes .\n",
      "mad pretty charge did lol . )\n",
      "seen going up . tip . flying . . and number ? .\n",
      "nothing mostly adding ass into\n",
      "abilities moving me abilities affect .\n",
      "running wanting feels i going stuff\n",
      "bar dick knowing events . understand .\n",
      "looking wonder one at . op .\n",
      "upset events upon it or . . skin your . . '' . . .\n",
      "loved directly of into it ! .\n",
      "road ) feedback alone seconds bad ca\n",
      "have old '' , . flying\n",
      "actual might list . allowed out ! all\n",
      "'re town term lower . )\n",
      "making counter ! it release you\n",
      "usually to road . ?\n",
      "! single site . and\n",
      "forces speech events the life it\n",
      "tree any board little her ? as . imo knowing .\n",
      "back though damage . you . . . is . ) .\n",
      "hp 15 move 12 use beyond . like .\n",
      "gt drug now areas . taxes\n",
      "listen issue 6 . to\n",
      "easy comfortable the dating .\n",
      "pass close the huge .\n",
      "center him content . . ? added . ? . not : ?\n",
      "asked what that . a . up\n",
      "did him today . game ? .\n",
      "baby video less . . they no\n",
      "taxes god do social yet\n",
      "twice box cheap ! this . hand . .\n",
      "lost asking speed specifically bad\n",
      "tools of insane . for to the our\n",
      "girlfriend performance track for ! .\n",
      "easily 60 written case .\n",
      "mod example him say .\n",
      "eventually nice guess ? .\n",
      "closer questions attack bowl and . . :\n",
      "subreddit talking name pro ?\n",
      "wondering highest policies . do .\n",
      "stand third people . : . the day . .\n",
      "via asshole quick ! turn option\n",
      "stay skills with point . the other\n"
     ]
    }
   ],
   "source": [
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "    \n",
    "def generate_sentence(model):\n",
    "    # We start the sentence with the start token\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    # Repeat until we get an end token\n",
    "    while not new_sentence[-1] == word_to_index[sentence_end_token]:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        sampled_word = word_to_index[unknown_token]\n",
    "        # We don't want to sample unknown words\n",
    "        while sampled_word == word_to_index[unknown_token]:\n",
    "            samples = np.random.multinomial(1, next_word_probs[-1])\n",
    "            sampled_word = np.argmax(samples)\n",
    "        new_sentence.append(sampled_word)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    return sentence_str\n",
    " \n",
    "num_sentences = 50\n",
    "senten_min_length = 5\n",
    " \n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        sent = generate_sentence(model)\n",
    "    print \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.000000 be . the . the\n",
      "-23.000000 to . for . the\n",
      "-23.000000 to . ? . the\n",
      "-23.000000 to . to . the\n",
      "-23.000000 to . the . the\n",
      "-23.000000 to . it . the\n",
      "-23.000000 to . is . the\n",
      "-23.000000 to . you . the\n",
      "-23.000000 to . a . the\n",
      "-23.000000 to . of . the\n",
      "-23.000000 to . as . the\n",
      "-24.000000 to . to . you\n",
      "-24.000000 to . it . ?\n",
      "-24.000000 to . it . a\n",
      "-24.000000 to . you . ,\n",
      "-24.000000 to . you . ?\n",
      "-24.000000 to . it . it\n",
      "-24.000000 to . is . !\n",
      "-24.000000 to . a . !\n",
      "-24.000000 to . to . ?\n",
      "-24.000000 to . you . !\n",
      "-24.000000 to . it . for\n",
      "-24.000000 to . a . ?\n",
      "-24.000000 to . to . to\n",
      "-24.000000 to . to . ,\n",
      "-24.000000 to . it . you\n",
      "-24.000000 to . you . it\n",
      "-24.000000 to . it . ,\n",
      "-24.000000 to . to . a\n",
      "-24.000000 to . to . it\n",
      "-24.000000 to . a . ,\n",
      "-24.000000 to . and . the\n",
      "-24.000000 to . a . for\n",
      "-24.000000 to . a . you\n",
      "-24.000000 to . is . ,\n",
      "-24.000000 to . to . of\n",
      "-24.000000 to . it . to\n",
      "-24.000000 to . it . of\n",
      "-24.000000 to . it . !\n",
      "-24.000000 to . to . for\n",
      "-24.000000 to . you . for\n",
      "-24.000000 to . to . !\n",
      "-25.000000 to it . ! .\n",
      "-25.000000 to . it . the\n",
      "-25.000000 to . is . the\n",
      "-25.000000 to it . of .\n",
      "-25.000000 to . for . the\n",
      "-25.000000 to . you . the\n",
      "-25.000000 to . as . the\n",
      "-25.000000 to . a . the\n"
     ]
    }
   ],
   "source": [
    "def generate_sentences(model, beam_size=50, max_length=6):\n",
    "    # We start the sentence with the start token and a random word\n",
    "    sentences = [[word_to_index[sentence_start_token]]]\n",
    "    sentence_probs = [0]\n",
    "    for i in range(max_length):\n",
    "        next_sentences = []\n",
    "        next_sentences_probs = []\n",
    "        for s, prob in zip(sentences, sentence_probs):\n",
    "            next_word_probs = np.log(model.forward_propagation(s))[-1]\n",
    "            next_words = np.argsort(next_word_probs)[-beam_size:][::-1]\n",
    "            for word in next_words:\n",
    "                if word != word_to_index[unknown_token] and word != word_to_index[sentence_end_token] and word != s[-1]:\n",
    "                    next_sentences.append(np.concatenate((s, [word])))\n",
    "                    next_sentences_probs.append(prob + next_word_probs[word])\n",
    "        next_sentences = np.array(next_sentences).astype('int32')\n",
    "        next_sentences_probs = np.array(next_sentences_probs).astype('int32')\n",
    "        top_sentences_idx = np.argsort(next_sentences_probs)[-beam_size:][::-1]\n",
    "        sentences = next_sentences[top_sentences_idx]\n",
    "        sentence_probs = next_sentences_probs[top_sentences_idx]\n",
    "    return sentences, sentence_probs\n",
    "        \n",
    "def print_senence(s):\n",
    "    sentence_str = [index_to_word[x] for x in s[1:-1]]\n",
    "    print \" \".join(sent)\n",
    "\n",
    "sentences, sentence_probs = generate_sentences(model)\n",
    "for sent, prob in zip(sentences, sentence_probs):\n",
    "    sentence_str = [index_to_word[x] for x in sent[1:-1]]\n",
    "    print \"%f %s\" % (prob, \" \".join(sentence_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
