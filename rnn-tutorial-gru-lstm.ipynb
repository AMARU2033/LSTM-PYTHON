{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import operator\n",
    "from theano.gradient import grad_clip\n",
    "from utils import *\n",
    "from lstm_theano import *\n",
    "from gru_theano import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "Parsed 70693 sentences.\n",
      "Found 57636 unique words tokens.\n",
      "Using vocabulary size 8000.\n",
      "The least frequent word in our vocabulary is 'labs' and appeared 9 times.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from utils import load_and_proprocess_data\n",
    "VOCABULARY_SIZE = 8000\n",
    "X_train, y_train, word_to_index, index_to_word = load_and_proprocess_data(VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do a gradient check\n",
    "np.random.seed(0)\n",
    "model = GRUTheano(100, 10)\n",
    "gradient_check_theano(model, [0,1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRUTheano:\n",
    "    \n",
    "    def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Randomly initialize the network parameters\n",
    "        U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (3, hidden_dim, word_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (3, hidden_dim, hidden_dim))\n",
    "        b = np.zeros((3, hidden_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        b2 = np.zeros(word_dim)\n",
    "        # Theano: Created shared variables\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        # Bias terms\n",
    "        self.b = theano.shared(name='b_i', value=b.astype(theano.config.floatX))\n",
    "        self.b2 = theano.shared(name='b_V', value=b2.astype(theano.config.floatX))\n",
    "        # SGD: Initialize parameters\n",
    "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
    "        self.mb2 = theano.shared(name='mb2', value=np.zeros(b2.shape).astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()\n",
    "    \n",
    "    def __theano_build__(self):\n",
    "        V, U, W, b, b2 = self.V, self.U, self.W, self.b, self.b2\n",
    "        # mV, mU, mW, mb, mb2 = self.mV, self.mU, self.mW, self.mb, self.mb2\n",
    "        \n",
    "        x = T.ivector('x')\n",
    "        y = T.ivector('y')\n",
    "        \n",
    "        def forward_prop_step(x_t, s_t_prev):\n",
    "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
    "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t_prev))\n",
    "            \n",
    "            # Clip the gradients\n",
    "            W_clipped = grad_clip(W, -1, 1)\n",
    "            U_clipped = grad_clip(U, -1, 1)\n",
    "            V_clipped = grad_clip(V, -1, 1)\n",
    "            b_clipped = grad_clip(b, -1, 1)\n",
    "            b2_clipped = grad_clip(b2, -1, 1)\n",
    "            \n",
    "            # LRU hidden state calculation\n",
    "            z_t = T.nnet.sigmoid(U_clipped[0][:,x_t] + W_clipped[0].dot(s_t_prev) + b_clipped[0])\n",
    "            r_t = T.nnet.sigmoid(U_clipped[1][:,x_t] + W_clipped[1].dot(s_t_prev) + b_clipped[1])\n",
    "            c_t = T.tanh(U_clipped[2][:,x_t] + W_clipped[2].dot(s_t_prev) * r_t + b_clipped[2])\n",
    "            s_t = (1 - z_t) * c_t + z_t * s_t_prev\n",
    "              \n",
    "            # Final output calculation\n",
    "            # Theano's softmax returns a matrix with one row, we only need the row\n",
    "            o_t = T.nnet.softmax(V_clipped.dot(s_t) + b2_clipped)[0]\n",
    "\n",
    "            return [o_t, s_t]\n",
    "        \n",
    "        [o,s], updates = theano.scan(\n",
    "            forward_prop_step,\n",
    "            sequences=x,\n",
    "            outputs_info=[None, dict(initial=T.zeros(self.hidden_dim))],\n",
    "            truncate_gradient=self.bptt_truncate)\n",
    "        \n",
    "        prediction = T.argmax(o, axis=1)\n",
    "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        \n",
    "        # Gradients\n",
    "        dU = T.grad(o_error, U)\n",
    "        dW = T.grad(o_error, W)\n",
    "        db = T.grad(o_error, b)\n",
    "        dV = T.grad(o_error, V)\n",
    "        db2 = T.grad(o_error, b2)\n",
    "        \n",
    "        # Assign functions\n",
    "        self.forward_propagation = theano.function([x], o)\n",
    "        self.predict = theano.function([x], prediction)\n",
    "        self.ce_error = theano.function([x, y], o_error)\n",
    "        self.bptt = theano.function([x, y], [dU, dW, db, dV, db2])\n",
    "        \n",
    "        # SGD parameters\n",
    "        learning_rate = T.scalar('learning_rate')\n",
    "        decay = T.scalar('decay')\n",
    "        \n",
    "        # rmsprop cache updates\n",
    "        mU = decay * self.mU + (1 - decay) * T.sqr(dU)\n",
    "        mW = decay * self.mW + (1 - decay) * T.sqr(dW)\n",
    "        mV = decay * self.mV + (1 - decay) * T.sqr(dV)\n",
    "        mb = decay * self.mb + (1 - decay) * T.sqr(db)\n",
    "        mb2 = decay * self.mb2 + (1 - decay) * T.sqr(db2)\n",
    "        \n",
    "        self.sgd_step = theano.function(\n",
    "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
    "            [], \n",
    "            updates=[(U, U - learning_rate * dU / T.sqrt(mU + 1e-8)),                     \n",
    "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-8)),\n",
    "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-8)),\n",
    "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-8)),\n",
    "                     (b2, b2 - learning_rate * db2 / T.sqrt(mb2 + 1e-8)),\n",
    "                     (self.mU, mU),\n",
    "                     (self.mW, mW),\n",
    "                     (self.mV, mV),\n",
    "                     (self.mb, mb),\n",
    "                     (self.mb2, mb2)\n",
    "                    ])\n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        return np.sum([self.ce_error(x,y) for x,y in zip(X,Y)])\n",
    "    \n",
    "    def calculate_loss(self, X, Y):\n",
    "        # Divide calculate_loss by the number of words\n",
    "        num_words = np.sum([len(y) for y in Y])\n",
    "        return self.calculate_total_loss(X,Y)/float(num_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Step time: 324.581146 milliseconds\n",
      "2015-10-17 00:03:35: Loss after num_examples_seen=0 epoch=0: 8.985473\n",
      "2015-10-17 00:05:49: Loss after num_examples_seen=500 epoch=1: 7.027176\n",
      "2015-10-17 00:07:55: Loss after num_examples_seen=1000 epoch=2: 7.100400\n",
      "Setting learning rate to 0.000500\n",
      "2015-10-17 00:10:00: Loss after num_examples_seen=1500 epoch=3: 6.919610\n",
      "2015-10-17 00:12:07: Loss after num_examples_seen=2000 epoch=4: 6.948866\n",
      "Setting learning rate to 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-52077ee310a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"SGD Step time: %f milliseconds\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# save_model_parameters_theano('data/mymodel.npz', model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/utils.py\u001b[0m in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, decay, evaluate_loss_after, subsample_loss, save_every)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# One SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mnum_examples_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    670\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/dennybritz/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4585)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load parameters of pre-trained model\n",
    "# model = load_model_parameters_theano('./data/pretrained.npz', GRUTheano)\n",
    "\n",
    "# Build model and train\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "NEPOCH = 50\n",
    "HIDDEN_DIM = 80\n",
    "\n",
    "model = GRUTheano(VOCABULARY_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[10], y_train[10], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print \"SGD Step time: %f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train[:500], y_train[:500], LEARNING_RATE, NEPOCH, evaluate_loss_after=1, decay=0.9)\n",
    "# save_model_parameters_theano('data/mymodel.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 even ) the to , .\n",
      "0.000000 post registered revolution the debate ? .\n",
      "0.000000 case matter all internet acting .\n",
      "0.000000 helped their friends development to it .\n",
      "0.000000 this my hundreds this or .\n",
      "0.000000 dog bound day the save .\n",
      "0.000000 chance head nope the it .\n",
      "0.000000 human basically '' the to .\n",
      "0.000000 them commit or the top .\n",
      "0.000000 their service same the of the it .\n",
      "0.000000 medicine walk '' the level .\n",
      "0.000000 didnt top in the short .\n",
      "0.000000 request apply the to , watch is this .\n",
      "0.000000 song vanilla making in you the .\n",
      "0.000000 far to ppl the , '' .\n",
      "0.000000 deep and pictures performed care .\n",
      "0.000000 more better fit to for is\n",
      "0.000000 suffer than units the super .\n",
      "0.000000 be titles as the concrete .\n",
      "0.000000 walking right and to the .\n",
      "0.000000 possibly players floor the in my .\n",
      "0.000000 choice standing = the scratch .\n",
      "0.000000 man officer with for to .\n",
      "0.000000 raids works , wing constant playing .\n",
      "0.000000 cant species bible the or .\n",
      "0.000000 the description sure west and .\n",
      "0.000000 racist therefore a with it .\n",
      "0.000000 perceived church lost and top .\n",
      "0.000000 superior happening parking and latter and .\n",
      "0.000000 release discussion content of station .\n",
      "0.000000 insecure section and her like .\n",
      "0.000000 records shit the to it .\n",
      "0.000000 completed lead att the about .\n",
      "0.000000 chain the anymore for companion .\n",
      "0.000000 benner for + the ) .\n",
      "0.000000 on later and be hour .\n",
      "0.000000 3. trying a remember as .\n",
      "0.000000 mental rude , in for to .\n",
      "0.000000 charges lol feature of game .\n",
      "0.000000 7 brain a -- than .\n",
      "0.000000 steel progress your in ? .\n",
      "0.000000 , into bad the ? .\n",
      "0.000000 act , less n't , .\n",
      "0.000000 eat everyone of honest /message/compose/ .\n",
      "0.000000 start leading reducing the of of .\n",
      "0.000000 launch 12 gotten is the .\n",
      "0.000000 fine de be you to internet .\n",
      "0.000000 remember longer ) to it .\n",
      "0.000000 elsewhere older fucking first not .\n",
      "0.000000 personal being role or viable .\n"
     ]
    }
   ],
   "source": [
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "    \n",
    "def generate_sentence(model):\n",
    "    # We start the sentence with the start token and a random word\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    prob = 1\n",
    "    while not new_sentence[-1] == word_to_index[sentence_end_token]:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        samples = np.random.multinomial(5, next_word_probs[-1])\n",
    "        sampled_word = np.argmax(samples)\n",
    "        prob = prob * next_word_probs[-1][sampled_word]\n",
    "        # Discard this sentence if we sample an unknown word\n",
    "        if sampled_word == word_to_index[unknown_token]:\n",
    "           return [1,[]]\n",
    "        new_sentence.append(sampled_word)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    return [prob, sentence_str]\n",
    " \n",
    "num_sentences = 50\n",
    "senten_min_length = 6\n",
    "sentences = []\n",
    "    \n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        prob, sent = generate_sentence(model)\n",
    "    print \"%f %s\" % (prob, \" \".join(sent))\n",
    "    sentences.append([prob, sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
