{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import operator\n",
    "from theano.gradient import grad_clip\n",
    "from utils import *\n",
    "from lstm_theano import *\n",
    "from gru_theano import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Stanford pre-trained glove vectors\n",
    "gdic, gvec = load_stanford_glove(\"data/glove/glove.6B.100d.txt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "Parsed 70693 sentences.\n",
      "Found 57636 unique words tokens.\n",
      "Using vocabulary size 2000.\n",
      "The least frequent word in our vocabulary is 'offensive' and appeared 54 times.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from utils import load_and_proprocess_data\n",
    "VOCABULARY_SIZE = 2000\n",
    "X_train, y_train, word_to_index, index_to_word = load_and_proprocess_data(VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct glove word vectors for vocabulary\n",
    "wv_dim = gvec.shape[1]\n",
    "wv = []\n",
    "for i in range(VOCABULARY_SIZE):\n",
    "    word = index_to_word[i]\n",
    "    if word not in gdic:\n",
    "        wv.append(np.zeros(wv_dim))\n",
    "    else:\n",
    "        wv.append(gvec[gdic[word]])\n",
    "wv = np.array(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do a gradient check\n",
    "np.random.seed(0)\n",
    "model = GRUTheano(100, 10)\n",
    "gradient_check_theano(model, [0,1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GRUTheano:\n",
    "    \n",
    "    def __init__(self, word_dim, hidden_dim=100, reg_lambda=0, wordvec=None):\n",
    "        # Assign instance variables\n",
    "        self.word_dim = word_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.reg_lambda = reg_lambda\n",
    "        # Initialize the network parameters\n",
    "        if wordvec != None:\n",
    "            U = np.array([wordvec.T, wordvec.T, wordvec.T])\n",
    "        else:\n",
    "            U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (3, hidden_dim, word_dim))\n",
    "        W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (3, hidden_dim, hidden_dim))\n",
    "        b = np.zeros((3, hidden_dim))\n",
    "        V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n",
    "        b2 = np.zeros(word_dim)\n",
    "        # Theano: Created shared variables\n",
    "        self.U = theano.shared(name='U', value=U.astype(theano.config.floatX))\n",
    "        self.W = theano.shared(name='W', value=W.astype(theano.config.floatX))\n",
    "        self.V = theano.shared(name='V', value=V.astype(theano.config.floatX))\n",
    "        # Bias terms\n",
    "        self.b = theano.shared(name='b_i', value=b.astype(theano.config.floatX))\n",
    "        self.b2 = theano.shared(name='b_V', value=b2.astype(theano.config.floatX))\n",
    "        # SGD: Initialize parameters\n",
    "        self.mU = theano.shared(name='mU', value=np.zeros(U.shape).astype(theano.config.floatX))\n",
    "        self.mV = theano.shared(name='mV', value=np.zeros(V.shape).astype(theano.config.floatX))\n",
    "        self.mW = theano.shared(name='mW', value=np.zeros(W.shape).astype(theano.config.floatX))\n",
    "        self.mb = theano.shared(name='mb', value=np.zeros(b.shape).astype(theano.config.floatX))\n",
    "        self.mb2 = theano.shared(name='mb2', value=np.zeros(b2.shape).astype(theano.config.floatX))\n",
    "        # We store the Theano graph here\n",
    "        self.theano = {}\n",
    "        self.__theano_build__()\n",
    "    \n",
    "    def __theano_build__(self):\n",
    "        V, U, W, b, b2 = self.V, self.U, self.W, self.b, self.b2\n",
    "        # mV, mU, mW, mb, mb2 = self.mV, self.mU, self.mW, self.mb, self.mb2\n",
    "        \n",
    "        x = T.ivector('x')\n",
    "        y = T.ivector('y')\n",
    "        \n",
    "        def forward_prop_step(x_t, s_t_prev):\n",
    "            # This is how we calculated the hidden state in a simple RNN. No longer!\n",
    "            # s_t = T.tanh(U[:,x_t] + W.dot(s_t_prev))\n",
    "            \n",
    "            # Clip the gradients\n",
    "            W_clipped = grad_clip(W, -1, 1)\n",
    "            U_clipped = grad_clip(U, -1, 1)\n",
    "            V_clipped = grad_clip(V, -1, 1)\n",
    "            b_clipped = grad_clip(b, -1, 1)\n",
    "            b2_clipped = grad_clip(b2, -1, 1)\n",
    "            \n",
    "            # LRU hidden state calculation\n",
    "            z_t = T.nnet.sigmoid(U_clipped[0][:,x_t] + W_clipped[0].dot(s_t_prev) + b_clipped[0])\n",
    "            r_t = T.nnet.sigmoid(U_clipped[1][:,x_t] + W_clipped[1].dot(s_t_prev) + b_clipped[1])\n",
    "            c_t = T.tanh(U_clipped[2][:,x_t] + W_clipped[2].dot(s_t_prev) * r_t + b_clipped[2])\n",
    "            s_t = (1 - z_t) * c_t + z_t * s_t_prev\n",
    "              \n",
    "            # Final output calculation\n",
    "            # Theano's softmax returns a matrix with one row, we only need the row\n",
    "            o_t = T.nnet.softmax(V_clipped.dot(s_t) + b2_clipped)[0]\n",
    "\n",
    "            return [o_t, s_t]\n",
    "        \n",
    "        [o,s], updates = theano.scan(\n",
    "            forward_prop_step,\n",
    "            sequences=x,\n",
    "            outputs_info=[None, dict(initial=T.zeros(self.hidden_dim))])\n",
    "        \n",
    "        prediction = T.argmax(o, axis=1)\n",
    "        o_error = T.sum(T.nnet.categorical_crossentropy(o, y))\n",
    "        \n",
    "        # Regularization cost\n",
    "        reg_cost = self.reg_lambda/2. * \\\n",
    "            (T.sum(T.sqr(V)) + T.sum(T.sqr(U)) + T.sum(T.sqr(W)) + T.sum(T.sqr(b)) + T.sum(T.sqr(b2)))\n",
    "        # Total cost\n",
    "        cost = o_error + reg_cost\n",
    "        \n",
    "        # Gradients\n",
    "        dU = T.grad(o_error, U)\n",
    "        dW = T.grad(o_error, W)\n",
    "        db = T.grad(o_error, b)\n",
    "        dV = T.grad(o_error, V)\n",
    "        db2 = T.grad(o_error, b2)\n",
    "        \n",
    "        # Assign functions\n",
    "        self.forward_propagation = theano.function([x], o)\n",
    "        self.predict = theano.function([x], prediction)\n",
    "        self.ce_error = theano.function([x, y], cost)\n",
    "        self.bptt = theano.function([x, y], [dU, dW, db, dV, db2])\n",
    "        \n",
    "        # SGD parameters\n",
    "        learning_rate = T.scalar('learning_rate')\n",
    "        decay = T.scalar('decay')\n",
    "        \n",
    "        # rmsprop cache updates\n",
    "        mU = decay * self.mU + (1 - decay) * T.sqr(dU)\n",
    "        mW = decay * self.mW + (1 - decay) * T.sqr(dW)\n",
    "        mV = decay * self.mV + (1 - decay) * T.sqr(dV)\n",
    "        mb = decay * self.mb + (1 - decay) * T.sqr(db)\n",
    "        mb2 = decay * self.mb2 + (1 - decay) * T.sqr(db2)\n",
    "        \n",
    "        self.sgd_step = theano.function(\n",
    "            [x, y, learning_rate, theano.Param(decay, default=0.9)],\n",
    "            [], \n",
    "            updates=[(U, U - learning_rate * dU / T.sqrt(mU + 1e-8)),                     \n",
    "                     (W, W - learning_rate * dW / T.sqrt(mW + 1e-8)),\n",
    "                     (V, V - learning_rate * dV / T.sqrt(mV + 1e-8)),\n",
    "                     (b, b - learning_rate * db / T.sqrt(mb + 1e-8)),\n",
    "                     (b2, b2 - learning_rate * db2 / T.sqrt(mb2 + 1e-8)),\n",
    "                     (self.mU, mU),\n",
    "                     (self.mW, mW),\n",
    "                     (self.mV, mV),\n",
    "                     (self.mb, mb),\n",
    "                     (self.mb2, mb2)\n",
    "                    ])\n",
    "    def calculate_total_loss(self, X, Y):\n",
    "        return np.sum([self.ce_error(x,y) for x,y in zip(X,Y)])\n",
    "    \n",
    "    def calculate_loss(self, X, Y):\n",
    "        # Divide calculate_loss by the number of words\n",
    "        num_words = np.sum([len(y) for y in Y])\n",
    "        return self.calculate_total_loss(X,Y)/float(num_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Step time: 589.647055 milliseconds\n",
      "2015-10-19 09:55:02: Loss after num_examples_seen=0 epoch=0: 7.623720\n",
      "2015-10-19 09:57:20: Loss after num_examples_seen=500 epoch=1: 5.460253\n",
      "2015-10-19 09:59:35: Loss after num_examples_seen=1000 epoch=2: 5.213818\n",
      "2015-10-19 10:01:49: Loss after num_examples_seen=1500 epoch=3: 5.093723\n",
      "2015-10-19 10:04:07: Loss after num_examples_seen=2000 epoch=4: 5.004667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7c7403a9828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"SGD Step time: %f milliseconds\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_loss_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# save_model_parameters_theano('data/mymodel.npz', model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/utils.py\u001b[0m in \u001b[0;36mtrain_with_sgd\u001b[0;34m(model, X_train, y_train, learning_rate, nepoch, decay, evaluate_loss_after, subsample_loss, save_every)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# One SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mnum_examples_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    670\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/dennybritz/.theano/compiledir_Darwin-14.5.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4585)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/wildml/rnn-tutorial-lstm/venv/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load parameters of pre-trained model\n",
    "# model = load_model_parameters_theano('./data/2015-10-18/GRUTheano-80-8000-10.npz', GRUTheano)\n",
    "\n",
    "# Build model and train\n",
    "\n",
    "REGULARIZATION = 0\n",
    "LEARNING_RATE = 1e-4\n",
    "NEPOCH = 50\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "model = GRUTheano(VOCABULARY_SIZE, hidden_dim=HIDDEN_DIM, reg_lambda=REGULARIZATION, wordvec=wv)\n",
    "\n",
    "t1 = time.time()\n",
    "model.sgd_step(X_train[10], y_train[10], LEARNING_RATE)\n",
    "t2 = time.time()\n",
    "print \"SGD Step time: %f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "\n",
    "train_with_sgd(model, X_train[:500], y_train[:500], LEARNING_RATE, NEPOCH, evaluate_loss_after=1, decay=0.9)\n",
    "# save_model_parameters_theano('data/mymodel.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000 drive there be wish gets shit ) than ) my\n",
      "0.000000 words get to they that than is try , if\n",
      "0.000000 insurance on a ? so that\n",
      "0.000000 to learning rather nearly of day this a day can .\n",
      "0.000000 for you , if imo place that\n",
      "0.000000 although and the , ( so shit they\n",
      "0.000000 bunch to of i people like .\n",
      "0.000000 equipment speed of they new and\n",
      "0.000000 increase ways mean my without but\n",
      "0.000000 vs ahead n't get to some of can\n",
      "0.000000 currently planet at just of decks get , one i you .\n",
      "0.000000 teams and ? feedback to .\n",
      "0.000000 shot thus ) they a much\n",
      "0.000000 available playing be in . enough ''\n",
      "0.000000 players angry , , i they ,\n",
      "0.000000 impossible line about about . on before and as with you . in vs option it\n",
      "0.000000 match comments being of teams play with\n",
      "0.000000 number is i not and 1. of n't\n",
      "0.000000 we basically we . this (\n",
      "0.000000 cap when ) a ) evil regularly it out .\n",
      "0.000000 viable . a just one for . the in n't in get much in of than\n",
      "0.000000 them own ; when was of it should .\n",
      "0.000000 claim interesting you , are 'd is . .\n",
      "0.000000 on , the 'm just of\n",
      "0.000000 with and but in you she the . what a test still more he\n",
      "0.000000 and your . a high first\n",
      "0.000000 gain knew be be 're . really with n't moved use like no ,\n",
      "0.000000 ad sweet the make to is really\n",
      "0.000000 how than that only it .\n",
      "0.000000 have if i up them n't . so remember\n",
      "0.000000 seconds road heart the most .\n",
      "0.000000 when again . with is on . n't more in 's 'm before on but like points much reality\n",
      "0.000000 enjoy . be the . get\n",
      "0.000000 tech 'll more about ( of instead come to attention\n",
      "0.000000 reply ) had no to was to who a the .\n",
      "0.000000 track child a something and remember . .\n",
      "0.000000 13 & you or and did\n",
      "0.000000 reaction competition `` background are to to everyone\n",
      "0.000000 got horrible that method a anyone ,\n",
      "0.000000 begin my in a and .\n",
      "0.000000 history ended just and if are .\n",
      "0.000000 but or bad up but 's place is . some for is to a can the it\n",
      "0.000000 date of he . , a be instead\n",
      "0.000000 however who them you would played that amount boring of out that .\n",
      "0.000000 o probably huge something is be\n",
      "0.000000 test of them the it the a for it that in\n",
      "0.000000 ads lead you because go the , ,\n",
      "0.000000 computer did , a but and\n",
      "0.000000 '' will . . play their ; that .\n",
      "0.000000 exists them solid young for used 's made there\n"
     ]
    }
   ],
   "source": [
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "    \n",
    "# TODO: Beam prediction\n",
    "def generate_sentence(model, beam_size=100, max_length=6):\n",
    "    # We start the sentence with the start token and a random word\n",
    "    new_sentence = [word_to_index[sentence_start_token]]\n",
    "    prob = 1\n",
    "    while not new_sentence[-1] == word_to_index[sentence_end_token]:\n",
    "        next_word_probs = model.forward_propagation(new_sentence)\n",
    "        samples = np.random.multinomial(1, next_word_probs[-1])\n",
    "        sampled_word = np.argmax(samples)\n",
    "        prob = prob * next_word_probs[-1][sampled_word]\n",
    "        # Discard this sentence if we sample an unknown word\n",
    "        if sampled_word == word_to_index[unknown_token]:\n",
    "           return [1,[]]\n",
    "        new_sentence.append(sampled_word)\n",
    "    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n",
    "    return [prob, sentence_str]\n",
    " \n",
    "\n",
    "num_sentences = 50\n",
    "senten_min_length = 6\n",
    "sentences = []\n",
    "    \n",
    "for i in range(num_sentences):\n",
    "    sent = []\n",
    "    # We want long sentences, not sentences with one or two words\n",
    "    while len(sent) < senten_min_length:\n",
    "        prob, sent = generate_sentence(model)\n",
    "    print \"%f %s\" % (prob, \" \".join(sent))\n",
    "    sentences.append([prob, sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
